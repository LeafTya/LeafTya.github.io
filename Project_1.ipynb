{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ef3758",
   "metadata": {},
   "source": [
    "# Project 1: NYC Air Quality Index Analysis\n",
    "### Welcome to my first project!\n",
    "\n",
    "Where do you live in the New York Metropolitan Area — the Upper West Side, Flushing, or maybe Rockaway Beach? Believe it or not, the air you breathe can be quite different depending on where you stand.\n",
    "\n",
    "In this project, I explore New York City’s Air Quality data from NYC Open Data focusing on Nitrogen Dioxide (NO₂) — one of the key pollutants that shape the city’s air health. Using Python, I clean and visualize the dataset to uncover how NO₂ levels change across neighborhoods, through seasons, and over the years.\n",
    "\n",
    "You’ll see how places like Flushing and the Upper West Side compare, whether winter air is really worse than summer’s, and how NYC’s air quality has evolved over the past decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a5e422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6eae0e",
   "metadata": {},
   "source": [
    "Here’s where we get picky with our data. First, we import the dataset and tell Python which number column we actually care about. Then we do a little data “housecleaning” — we only keep the rows that talk about Nitrogen dioxide (NO₂) in 2023, and only for the UHF42 areas (a fancy way of saying the 42 neighborhoods that make up NYC). Basically, we’re trimming out all the extra stuff so we can zoom in on the data that really matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d59ff761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the dataset, specify the filename and the target numerical column\n",
    "df = pd.read_csv('Air_Quality.csv')\n",
    "target_column = 'Data Value'\n",
    "\n",
    "# To filter the dataset to get the rows \n",
    "# where 'Name' is 'Nitrogen dioxide (NO2)' \n",
    "# and 'Time Period' is 'Annual Average 2023'\n",
    "# and 'Geo Type' is 'UHF42' which divides NYC into 42 distinct neighborhoods\n",
    "filtered_df = df[(df['Name'] == 'Nitrogen dioxide (NO2)') & \n",
    "                 (df['Time Period'] == 'Annual Average 2023') &\n",
    "                 (df['Geo Type Name'] == 'UHF42')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284fc4d",
   "metadata": {},
   "source": [
    "## Computing Mean, Median, and Mode\n",
    "### Pandas Approach\n",
    "Now that we’ve got our cleaned-up dataset, it’s time to get a quick “data vibe check.” Using pandas, we calculate the mean, median, and mode of our target column to see what the typical air quality values look like. These three stats give us a snapshot of the overall trend — the average level, the middle point, and the most common value. It’s a simple but powerful way to get a feel for the data before diving into visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "09668139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 16.79\n",
      "Median: 16.37\n",
      "Mode (Pandas): 18.41\n"
     ]
    }
   ],
   "source": [
    "# Calculating mean, median, and mode using pandas\n",
    "mean_value = filtered_df[target_column].mean()\n",
    "median_value = filtered_df[target_column].median()\n",
    "mode_pandas = filtered_df[target_column].mode()[0]\n",
    "\n",
    "print(f\"Mean: {mean_value:.2f}\")\n",
    "print(f\"Median: {median_value:.2f}\")\n",
    "print(f\"Mode (Pandas): {mode_pandas:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b9ef6",
   "metadata": {},
   "source": [
    "### Hard Way Approach\n",
    "Here, we’re getting hands-on and calculating the mean, median, and mode from scratch — no shortcuts with pandas this time!\n",
    "\n",
    "First, we pull the numbers we need from our filtered dataset and store them in a list (dropping any missing values along the way). Then:\n",
    "Mean: We add everything up and divide by the number of data points — the good old average.\n",
    "Median: We sort the list and find the middle value. If there’s an even number of values, we take the average of the two middle ones.\n",
    "Mode: We count how often each value appears and pick the one(s) that show up the most. If every value is unique, we note that there’s no mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "30af18fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 16.79\n",
      "Median: 16.37\n",
      "Mode (Hard Way): [18.41]\n"
     ]
    }
   ],
   "source": [
    "# Extract the data from filtered_df into a list\n",
    "data = filtered_df[target_column].dropna().tolist()\n",
    "\n",
    "# Calculate Mean (average)\n",
    "def calculate_mean(data):\n",
    "    # Sum all values and divide by count\n",
    "    total = sum(data)\n",
    "    count = len(data)\n",
    "    return total / count\n",
    "\n",
    "mean_value = calculate_mean(data)\n",
    "print(f\"Mean: {mean_value:.2f}\")\n",
    "\n",
    "\n",
    "# Calculate Median (middle value)\n",
    "def calculate_median(data):\n",
    "    # Sort the data first\n",
    "    sorted_data = sorted(data)\n",
    "    n = len(sorted_data)\n",
    "    \n",
    "    # If odd number of elements, return middle one\n",
    "    if n % 2 == 1:\n",
    "        return sorted_data[n // 2]\n",
    "    # If even number of elements, return average of two middle ones\n",
    "    else:\n",
    "        mid1 = sorted_data[n // 2 - 1]\n",
    "        mid2 = sorted_data[n // 2]\n",
    "        return (mid1 + mid2) / 2\n",
    "\n",
    "median_value = calculate_median(data)\n",
    "print(f\"Median: {median_value:.2f}\")\n",
    "\n",
    "\n",
    "# Calculate Mode (most frequent value)\n",
    "def calculate_mode(data):\n",
    "    # Count frequency of each value\n",
    "    frequency = {}\n",
    "    for value in data:\n",
    "        if value in frequency:\n",
    "            frequency[value] += 1\n",
    "        else:\n",
    "            frequency[value] = 1\n",
    "    \n",
    "    # Find maximum frequency\n",
    "    if not frequency:\n",
    "        return None\n",
    "    \n",
    "    max_freq = max(frequency.values())\n",
    "    \n",
    "    # Find all values with maximum frequency\n",
    "    modes = [key for key, freq in frequency.items() if freq == max_freq]\n",
    "    \n",
    "    # If all values appear only once, there's no mode\n",
    "    if max_freq == 1:\n",
    "        return \"No mode (all values appear only once)\"\n",
    "    \n",
    "    return modes\n",
    "\n",
    "mode_value = calculate_mode(data)\n",
    "print(f\"Mode (Hard Way): {mode_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1667d00a",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afeb5f",
   "metadata": {},
   "source": [
    "Now we finally turn our data into something visual. Everything has to be done using only the Python standard library, which means we’ll “draw” our chart using text symbols! In this step, we first grab the neighborhood names and their corresponding NO₂ values from the filtered dataset, clean out any missing entries, and sort them from highest to lowest pollution levels.\n",
    "\n",
    "Then, we calculate two thresholds — the 33rd and 67th percentiles — which divide all the neighborhoods into three groups:\n",
    "High pollution (H) – above the 67th percentile\n",
    "Medium pollution (M) – between the 33rd and 67th percentiles\n",
    "Low pollution (L) – below the 33rd percentile\n",
    "\n",
    "Next comes the fun part: for each neighborhood, we print a little text-based bar chart right in the terminal. The bar’s length reflects how high the NO₂ value is, and we use different symbols for each pollution level:\n",
    "\n",
    "High pollution #\n",
    "\n",
    "Medium pollution =\n",
    "\n",
    "Low pollution -\n",
    "\n",
    "This gives us a quick, visual way to compare air quality across NYC neighborhoods. Finally, we summarize how many neighborhoods fall into each category, giving a neat overview of the city’s 2023 NO₂ levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1b604fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      " NYC NEIGHBORHOODS - NO2 POLLUTION LEVELS (2023 Annual Avg)\n",
      "=================================================================\n",
      " HIGH >= 17.43  |  MEDIUM 15.50-17.43  |  LOW < 15.50\n",
      "-----------------------------------------------------------------\n",
      "[H] Chelsea - Clinton      |############################## 24.13\n",
      "[H] Gramercy Park - Murray |############################# 23.60\n",
      "[H] Greenwich Village - So |########################### 22.07\n",
      "[H] Lower Manhattan        |########################## 21.61\n",
      "[H] Greenpoint             |######################## 19.32\n",
      "[H] Sunset Park            |####################### 19.11\n",
      "[H] Upper East Side        |####################### 18.98\n",
      "[H] Union Square - Lower E |####################### 18.97\n",
      "[H] Long Island City - Ast |###################### 18.41\n",
      "[H] West Queens            |###################### 18.41\n",
      "[H] Upper West Side        |###################### 18.38\n",
      "[H] Downtown - Heights - S |###################### 18.29\n",
      "[H] Williamsburg - Bushwic |###################### 18.16\n",
      "[H] Hunts Point - Mott Hav |##################### 17.53\n",
      "[M] East New York          |===================== 17.34\n",
      "[M] Crotona -Tremont       |===================== 17.27\n",
      "[M] High Bridge - Morrisan |===================== 17.08\n",
      "[M] Washington Heights     |===================== 17.05\n",
      "[M] Bedford Stuyvesant - C |===================== 16.99\n",
      "[M] Ridgewood - Forest Hil |==================== 16.73\n",
      "[M] Bensonhurst - Bay Ridg |==================== 16.39\n",
      "[M] Borough Park           |==================== 16.35\n",
      "[M] East Harlem            |==================== 16.34\n",
      "[M] Central Harlem - Morni |==================== 16.29\n",
      "[M] Port Richmond          |==================== 16.28\n",
      "[M] East Flatbush - Flatbu |==================== 16.15\n",
      "[M] Stapleton - St. George |=================== 15.90\n",
      "[M] Pelham - Throgs Neck   |=================== 15.57\n",
      "[L] Jamaica                |------------------- 15.43\n",
      "[L] Flushing - Clearview   |------------------- 15.34\n",
      "[L] Southwest Queens       |------------------- 15.33\n",
      "[L] Fresh Meadows          |------------------ 15.20\n",
      "[L] Fordham - Bronx Pk     |------------------ 15.00\n",
      "[L] Bayside - Little Neck  |------------------ 14.93\n",
      "[L] Canarsie - Flatlands   |------------------ 14.86\n",
      "[L] Southeast Queens       |------------------ 14.69\n",
      "[L] Kingsbridge - Riverdal |------------------ 14.61\n",
      "[L] Northeast Bronx        |------------------ 14.48\n",
      "[L] Coney Island - Sheepsh |----------------- 13.95\n",
      "[L] Willowbrook            |--------------- 12.78\n",
      "[L] South Beach - Tottenvi |------------- 10.46\n",
      "[L] Rockaways              |----------- 9.38\n",
      "-----------------------------------------------------------------\n",
      " SUMMARY: [H] High: 14  |  [M] Medium: 14  |  [L] Low: 14\n",
      " TOTAL NEIGHBORHOODS: 42\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the filtered data with place names\n",
    "place_data = filtered_df[['Geo Place Name', target_column]].dropna()\n",
    "place_data = place_data.sort_values(by=target_column, ascending=False)\n",
    "\n",
    "# Calculate thresholds for grouping\n",
    "q33 = place_data[target_column].quantile(0.33)\n",
    "q67 = place_data[target_column].quantile(0.67)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\" NYC NEIGHBORHOODS - NO2 POLLUTION LEVELS (2023 Annual Avg)\")\n",
    "print(\"=\"*65)\n",
    "print(f\" HIGH >= {q67:.2f}  |  MEDIUM {q33:.2f}-{q67:.2f}  |  LOW < {q33:.2f}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "max_val = place_data[target_column].max()\n",
    "scale = 30 / max_val  # Scale bars to max 30 characters for narrow screens\n",
    "\n",
    "for idx, row in place_data.iterrows():\n",
    "    place_name = row['Geo Place Name']\n",
    "    value = row[target_column]\n",
    "    bar_length = int(value * scale)\n",
    "    \n",
    "    # Determine pollution level and use different symbols\n",
    "    if value >= q67:\n",
    "        bar = '#' * bar_length      # High: hash marks\n",
    "        level = 'H'\n",
    "    elif value >= q33:\n",
    "        bar = '=' * bar_length      # Medium: equals\n",
    "        level = 'M'\n",
    "    else:\n",
    "        bar = '-' * bar_length      # Low: dashes\n",
    "        level = 'L'\n",
    "    \n",
    "    # Truncate long names to fit narrow screen\n",
    "    display_name = place_name[:22].ljust(22)\n",
    "    print(f\"[{level}] {display_name} |{bar} {value:.2f}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"-\"*65)\n",
    "high_count = len(place_data[place_data[target_column] >= q67])\n",
    "medium_count = len(place_data[(place_data[target_column] >= q33) & \n",
    "                               (place_data[target_column] < q67)])\n",
    "low_count = len(place_data[place_data[target_column] < q33])\n",
    "\n",
    "print(f\" SUMMARY: [H] High: {high_count}  |  [M] Medium: {medium_count}  |  [L] Low: {low_count}\")\n",
    "print(f\" TOTAL NEIGHBORHOODS: {len(place_data)}\")\n",
    "print(\"=\"*65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
